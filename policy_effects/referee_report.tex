\documentclass{article}
\usepackage{amsmath} 
\usepackage{amsfonts}
\usepackage{booktabs}
\usepackage[a4paper, margin=2.5cm]{geometry}
\usepackage{float}   % for [H]
\usepackage{graphicx}   % for \includegraphics
\usepackage{tabularx}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{blindtext}
\usepackage{hyperref}
\usepackage{natbib} % <-- NEW: to handle references
\usepackage{setspace}
\usepackage{array}
\usepackage{dcolumn}
\usepackage{threeparttable}
\usepackage{tikz}
\usepackage{amsmath}
\usetikzlibrary{decorations.pathreplacing}
\usepackage{pdflscape} % in your preamble
\usepackage{tabularray}
\setcounter{secnumdepth}{2}
\usepackage{amsmath, amsthm}  % for math and theorem environments
\setlength{\parskip}{0.45em}   % space between paragraphs
\setlength{\parindent}{0pt}    % optional: remove paragraph indentation

\usepackage{titlesec}

\titlespacing*{\section}
{0pt}      % left margin
{1.0em}    % space before section
{0.5em}    % space after section


\begin{document}

\title{Referee Report: Dynamic college admissions (Larroucau/Ríos 2026)}
\author{Jordi Torres}
\date{\today}


\maketitle


\section*{1: Summary} 
In this paper, \citep{LarroucauRiosDynamicCollegeAdmissions} develop a dynamic structural model to study student's decisions to drop out or change degrees during higher education, and to evaluate how application and re-application systems can be designed to improve incentives and overall welfare. They focus on the centralized college admissions system in Chile, where students apply through a common platform and can later switch programs. In this setting, switching and dropout are quantitatively important: about 21 \% of students switch and 15 \% drop out. 

They identify two main behavioral channels behind these patterns. First, initial mismatching: not being assigned to one’s top-reported preference may increase the probability of re-application and later switching. Second, learning: students may update their preferences during college as they learn about their skills and match quality. These channels have different implications: if mismatches dominate, systems should penalize switching to internalize crowd-out externalities; if learning dominates, more flexibility in switching is desirable. 

Using their estimated structural model, they find that initial mismatches explain the majority of switching behavior, while learning accounts for about one-third of all switches. They then conduct counterfactual experiments to study how alternative information designs and application/switching rules help decrease drop out and switching. 

\section*{2: Reduced Form}
To separate the two main channels highlighted above, the paper exploits the quasi-random variation generated by admission cutoffs in Chile’s centralized college assignment system. Applicants are ranked by a composite score, and each program \(p\) admits students above a cutoff. 

They run regressions of the form
\[
y_{bp} = f_p(d_{bp}) + \delta_p Z_{bp} + \varepsilon_{bp},
\]
where \(y_{bp}\) denotes outcomes such as switching or dropout for applicants to program \(p\) in bins \(b\) of distance to the cutoff, \(Z_{bp}\) is an indicator for being above the cutoff, and \(f_p(\cdot)\) is a flexible function of the running variable (score).

Under the standard continuity assumption that potential outcomes vary smoothly at the cutoff, \(\delta_p\) identifies the causal effect of marginal admission priority on subsequent choices. Because crossing the cutoff does not mechanically imply enrollment, the design is fuzzy and \(\delta_p\) is interpreted as an intention to treat effect (ITT). This interpretation is addequate, as the object of interest is how admission priority affects students continuation values and dynamic decisions, rather than enrollment per se\footnote{They also implicitly assume there is no manipulation at tehe cutoff, which is defensible because scores are realized before cutoffs and cutoffs depend on capacity of schools; that SUTVA holds locally -i.e partial equilibrium-}.

Using this design, the authors show that being just below the cutoff for a top-ranked program significantly increases the probability of re-application and switching in subsequent periods, providing clean reduced-form evidence that quantifies the initial mismatch channel.



\section*{3: Structural Model}
The central contribution of the paper is to disentangle initial mismatch at entry from subsequent learning about ability and preferences. This section focuses on how the structural model isolates learning dynamics—both in beliefs about academic ability and in evolving tastes—from initial sorting into programs.

In each period \(t\), student \(i\) is enrolled in a program \(j\) associated with major
\(m(j)\). 

Students have imperfect information about their idiosyncratic tastes for majors.
Preferences for majors evolve according to:
\[
\alpha_{i,m,t+1}
=
\alpha_{i,m,t}
+
\mathbf{1}\{m=m(j)\}\,\varepsilon_{i,m,t}^{\alpha},
\qquad
\varepsilon_{i,m,t}^{\alpha}\sim\mathcal{N}(0,\zeta_{\alpha}^2),
\]

Student ability in program \(j\) has an observed component \(A^o\), a private component \(A^p\) —known only to the student, not by the analyst—, and an unknown component \(A^u\) learned over time:
\[
A_{ij}=A(A^o_{ij},A^p_{ij},A^u_{ij})
\]

Students hold subjective (potentially biased) priors over \(A^u\), summarized by a program-level mean \(\tilde{\mu}_{i,j,t}\) and variance \(\tilde{\sigma}_{i,j,t}^2\), which are updated over time using grade realizations:
\[
G_{i,j,t}=G(X^G_{i,j},A^p_{i,j},A^u_{i,j},\varepsilon^G_{i,j,t}), 
\qquad \varepsilon^G_{i,j,t}\sim\mathcal{N}(0,\sigma_G^2),
\]
with posterior beliefs evolving by Bayes' rule (Proposition 1). \\

Per-period flow utility depends on observed characteristics and major tastes, plus an i.i.d. Type-I extreme value shock:
\[
U_{i,j,t}=U(X^U_{i,j},\alpha_{i,m(j),t},\varepsilon^U_{i,j,t}). 
\]

Upon graduation, utility includes both non-pecuniary terms (loading on preferences and abilities) and the present value of earnings:
\[
V_{i,j,t'} = V^{NP}_{i,j,t'}(\alpha_{i,m(j),t'},A^o_{i,j},A^p_{i,j}+A^u_{i,j}) + V^{P}_{i,j,t'}(\text{expected wages}).
\]

The model is estimated by Simulated Method of Moments (SMM), matching moments from grades, enrollment/switching dynamics, survey measures of beliefs/preferences, and the reduced-form RD effects.

\textbf{Identification of learning} relies on three main sources of variation: first, initial application rankings help recover private ability \(A_{ij}^p\) and comparative advantage across programs, following \citet{arcidiacono_ability_2004-1}. Conditional on observables, rankings serve as a control for endogenous sorting. Second, among non-switchers, differences in the variance of grade residuals across periods separately identify persistent unknown ability \(A_{ij}^u\) and transitory grade noise \(\sigma_G^2\). Third, switching behavior conditional on non informative grades identifies the variance of preference shocks \(\zeta_{\alpha}^2\), as switching in the absence of ability signals reflects taste uncertainty rather than learning about ability. 


\textbf{Counterfactual information structures.}
The estimated model is used to study alternative information environments:
(i) \(\zeta_{\alpha}=0\), eliminating preference uncertainty; and
(ii) \((\tilde{\mu}_{i,j},\tilde{\sigma}_{i,j}^2)=(0,0)\), eliminating biased beliefs about unknown ability and transfering them to private ability.



\section*{4: Intersection Model-RF}
Let \(\Delta^{RD}\) denote the discontinuity in switching or dropout at an admission cutoff. The structural model is "disciplined" to reproduce \(\Delta^{RD}\), which fixes the magnitude of switching induced by marginal admission priority. Importantly, this limits how much switching the model can attribute to mismatch in total. In turn, this also limits the scope for learning-driven mechanisms to explain switching beyond what is already implied by initial assignment.

Without the structural model, the RD would only deliver local treatment effects at the cutoff. While being informative about the local causal impact of marginal assignment, the RD alone cannot distinguish if global switching is driven by initial mismatch or by learning —and can't separate learning about ability/preferences—. More importantly, it can not be used to evaluate more ambitious questions: e.g downstream effects of counterfactual admission rules/changes in information regimes that shift cutoffs and generate equilibrium re-sorting.

On the other hand, without the RD, the structural model would lack quasi-experimental variation disciplining the magnitude of mismatch effects. Given that the model exploits similar sources of information (which are generated by endogeneous decisions) —grades, switching behavior, and belief data— to estimate a large number of parameters in a highly demanding framework, this clean source of variation is essential to reduce dependence on modelling choices and to provide a cleaner argument. 

\section*{5: Strengths}
A particular strength of the paper —besides the central idea of using RD variation to discipline the model in the key mechanisms— is how heterogeneity is incorporated into the learning process. This is especially important for the counterfactuals on information provision, as information treatment can have very heterogeneous impact among different students. In the model, information policies operate by changing beliefs, and both belief updating and choices are nonlinear functions of prior means, prior variances, and preference uncertainty. As a result, average effects can be misleading (result of the nonlinearities), and conditioning on heterogeneity is necessary to correctly aggregate counterfactual outcomes on key levels of heterogeneity.

Heterogeneity enters the model through systematic differences in learning parameters, conditioned on observable characteristics. In particular, for each student \(i\) and component \(k \in M \cup S\), beliefs about unknown ability satisfy
\[
A_{i,k}^u \sim \mathcal{N}(\tilde{\mu}_{i,k}, \tilde{\sigma}_{i,k}^2),
\]
where both \(\tilde{\mu}_{i,k}\) and \(\tilde{\sigma}_{i,k}^2\) are modeled as linear functions of gender, income status, and average observed ability. A similar specification is used for preference parameters \((\mu_{\alpha,i,m}, \sigma_{\alpha,i,m}, \zeta_{\alpha,i,m}^2)\).

Key conclusions are based on this heterogeneity in learning and uncertainty. In particular, the paper shows that information policies have highly uneven effects across students, with larger impacts for certain individuals who enter college with greater uncertainty about their ability or preferences. This seems fundamental to guide future research.

\section*{6: Limitations}
However, the paper has some limitations :

\textbf{1. Mechanical separation between ability and preferences.}  
The distinction between learning about ability and learning about preferences is largely mechanical and model-built. Ability learning operates through updates to $A_{ij}^u$, driven by grade surprises $G_{ijt}-\mathbb{E}[G_{ijt}]$. However, interpreting this object as ability learning is unclear: grade realizations may also reflect endogenous effort, motivation, disengagement, or strategic behavior, none of which are modeled. Thus, the grade signal mixes multiple mechanisms. For example, a student who anticipates low returns or plans to reapply may optimally reduce effort in period $t$, generating a negative grade surprise that the model interprets as low ability rather than an endogenous response. This could be solved by adding unobserved latent types, like \citep{arcidiacono2025college}.

What the paper calls preference learning is defined residually as any component of utility not explained by grades; it is unclear why this should reflect preferences \footnote{Identification of "preferences" shocks also rely on the assumption that switches after noninformative grade shocks are due to changes in preferences. This is dubious, because a noninformative signal may still convey information on ability -i.e student confirms he has fit for the program}.  More importantly, the result that ability learning dominates preference learning is mechanically implied by the model: grade signal affects grades, continuation values, graduation, and wages, while preferences enter only through flow utility (after conditioning on program fixed effects) and continuation value through only one linear term. Thus the relative importance of the two channels is largely built in by the model structure.

\medskip

\noindent
\textbf{2. Weak information counterfactuals.}  The two CF on information are good to quantify the relative importance of both types of learning but have no policy bite. This does not seem a relevant contribution, as a similar exercise was done by \citet{arcidiacono2025college}.  

For example, “counseling” (similarly for the “1 year HS gap”) is modeled by shutting down preference uncertainty (setting the variance of $\gamma_{ijt}$ to zero). In practice, counseling would more plausibly affect beliefs about objective outcomes (e.g., labor market returns or dropout risks) or help students better articulate their tastes, rather than eliminating a residual preference shock under an implicit assumption of perfectly informative and trusted advice. As a result, the counterfactual does not map cleanly into a realistic information policy. 

Maybe it would be better to present the accounting exercise and then focus on the second set of CF, which are more meaningful and solid.

\medskip

\noindent
\textbf{3. Policy-invariant strategic behavior.}  The counterfactuals also rely on a fixed share of strategic applicants, $\rho$. Even if the identification of $\rho$ under the baseline is accepted\footnote{Identification relies on strong assumptions too.}, assuming that $\rho$ is invariant to policy changes is strong. Application rules/Information treatment plausibly affect incentives to acquire information and/or behave strategically. Presenting results under alternative values of $\rho$ does not resolve this issue, since all parameters are estimated conditional on a fixed behavioral regime. However, endogeneizing $\rho$ is maybe asking too much of this data.

\medskip

\noindent
\textbf{4. Switching outside the initial choice set.}  A striking fact is that about $67\%$ of students who switch move to programs outside their initial rank-order list, compared to only $33\%$ who move within the list. This suggests evolving choice sets or option discovery, rather than reordering preferences over a fixed set of alternatives. This pattern complicates the interpretation of initial mismatch and, surprisingly, is not addressed by the model or considered at all. This is puzzling and undermines their key source of variation; so at least they should provide more explanation on this.

\medskip

\noindent
\textbf{5. Stationarity of beliefs across cohorts.}  Belief and preference data from cohorts surveyed in 2022-2024 are used to identify parameters for the 2014 cohort under a conditional stationarity assumption. Given large changes in macroeconomic conditions, labor market returns, and information environments over this period, this assumption is strong. Since beliefs play a central role in the model (they enter everywhere), deviations from stationarity could affect the estimated learning dynamics and counterfactuals. More discussion on this assumption in the paper is necessary (it is hidden in the appendix).

\medskip

\noindent


\section*{7: Conclusion}
\citet{LarroucauRiosDynamicCollegeAdmissions} contribute to a growing literature in the economics of education that studies how students make decisions under uncertainty and imperfect information \citep{stinebrickner2012learning,stinebrickner2014academic,wiswall_zafar_good,arcidiacono2025college}. Importantly, the paper advances the methodological frontier by building an ambitious dynamic model in which switching and dropout respond to two distinct mechanisms—initial mismatch and learning—and in which heterogeneity plays a key role. Notably, it is among the first papers in this literature to explicitly embed a causal research design within the estimation of a structural model.

At the same time, this class of models often face two usual challenges, and the this paper is no exception. First, although they are good at quantifying the role uncertainty in such decision-making processes, information-policy counterfactuals are sometimes difficult to interpret as concrete interventions. Second, most applications focus on university settings, where students priors may be already relatively informed. Less attention has been devoted to earlier stages—such as high school—where tracking decisions and program choices are made under more uncertainty and where those early choices may lock in later paths.

My research agenda is to take this more seriously and in a high-school context. I am interested in modeling counseling and advice as a signal that is endogeneous (teacher/counselor quality, incentives, potential bias) and has heterogeneous take-up/trust by students and families. More generally, my goal is to use such a framework to ask how counseling systems should be designed to reduce mismatch at early margins and improve downstream outcomes.





\bibliographystyle{apalike}

\bibliography{bibliography}

\end{document}

